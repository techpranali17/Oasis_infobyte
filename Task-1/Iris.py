# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IMd0OBfDgKIIpV5tGiM9FJTxY6zBOsDO
"""

import numpy as np

import gdown

import pandas as pd

import matplotlib.pyplot as plt

import seaborn as sns

from wordcloud import WordCloud ,STOPWORDS

import missingno as msno

from datetime import datetime

import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler

from sklearn.preprocessing import OneHotEncoder

from sklearn.model_selection import train_test_split

from sklearn.model_selection import RandomizedSearchCV

from sklearn.model_selection import GridSearchCV

from sklearn.model_selection import cross_val_score

from sklearn.linear_model import LinearRegression

from sklearn.linear_model import Ridge

from sklearn.linear_model import Lasso

from sklearn import metrics

from sklearn.metrics import r2_score

from sklearn.metrics import mean_squared_error

from google.colab import drive
drive.mount('/content/drive')

file_id = "1fmBI7cP7OMvZ9hLv_RB0EwzzzEGYvrUF"

# Download the file from Google Drive
url = f"https://drive.google.com/uc?id={file_id}"
output = "file_name.csv" # Replace file_name.csv with the desired name for the downloaded file
gdown.download(url, output, quiet=False)

# Now read the downloaded CSV file
iris = pd.read_csv("file_name.csv") # Make sure to use the same file name here

# removing unnecessary column
iris.drop(columns=["Id"],inplace=True)

#info of dataset
iris.info()

#Summary statistics of Iris dataset
#info of dataset
iris.info()

#To get no. of rows and columns in the dataset
iris.shape

# Dropping duplicate values if any present in our dataframe meanwhile retaining the first value
iris=iris.drop_duplicates(keep='first')

# Dataset Duplicate Value Count
iris.duplicated().sum()

# Dataset Duplicate Value Count
iris.duplicated().sum()

# Check Unique Values for each variable.
def unique_values(df):
    for col in df.columns:
        unique_count = df[col].nunique()
        a=print(f"COLUMN NAME ({col}): {unique_count} unique values")
    return a
unique_values(iris)

# constructing a piechart to see the count of each species
plt.rcParams['figure.figsize']=(8,8)
plt.pie(iris['Species'].value_counts(),labels=['Iris-setosa','Iris-versicolor','Iris-virginica '],explode= [0.08, 0, 0],autopct='%1.1f%%',shadow=True);
plt.legend(bbox_to_anchor=(0,1));

#Pairplot which shows the pair-wise relation between every attributes
sns.pairplot(iris,hue='Species', height=3);

# Select only numeric columns
numeric_iris = iris.select_dtypes(include=np.number)

# Calculate the correlation matrix for numeric columns
plt.figure(figsize=(22, 10))
plt.title("Correlation Heatmap")
sns.heatmap(numeric_iris.corr(), annot=True, cmap='Spectral_r');

# splitting data into train and test set
x =  iris.drop('Species',axis=1)
y = iris['Species']
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2,random_state =42)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

# Define the hyperparameter grid for RandomSearchCV
param_grid = {
     'n_estimators': np.arange(50, 201, 10),
    'max_depth': [None] + list(np.arange(10, 21, 2)),
    'min_samples_split': np.arange(2, 11),
    'min_samples_leaf': np.arange(1, 5)
}
# Create the Random Forest classifier
rf_classifier = RandomForestClassifier()

# Performing RandomSearchCV to find the best hyperparameters
random_search = RandomizedSearchCV(
    estimator=rf_classifier, param_distributions=param_grid,
    n_iter=50, cv=5, n_jobs=-1, random_state=42
)
random_search.fit(x_train, y_train)

# Get the best hyperparameters and the best model
best_params = random_search.best_params_
best_rf_model = random_search.best_estimator_

# Evaluating the model
y_pred = best_rf_model.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Best hyperparameters:", best_params)
print("Accuracy:",accuracy)
print("Accuracy Score:",accuracy_score(y_test,y_pred)*100)

from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
cm=confusion_matrix(y_pred,y_test)
plt.figure(figsize=(10,8))
sns.heatmap(cm,annot=True)
plt.xlabel('predicted-y')
plt.ylabel('actual-y')
plt.show()

import xgboost as xgb

# Create the XGBoost classifier
xgb_classifier = xgb.XGBClassifier()

# Define the hyperparameter distribution for RandomizedSearchCV
param_distributions = {
    'n_estimators': np.arange(50, 201, 10),
    'max_depth': np.arange(3, 11),
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'min_child_weight': np.arange(1, 6),
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3, 0.4],
    'reg_alpha': [0, 0.01, 0.1, 1, 10],
    'reg_lambda': [0, 0.01, 0.1, 1, 10]
}

# Perform RandomizedSearchCV to find the best hyperparameters
random_search_cv = RandomizedSearchCV(
    estimator=xgb_classifier, param_distributions=param_distributions,
    n_iter=50, cv=5, n_jobs=-1, random_state=42
)

# Convert class labels to integers using LabelEncoder
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# train test split for XG boost
X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# using random search cv
random_search_cv.fit(X_train, Y_train)

# finding out the best parameter
best_params_xg = random_search_cv.best_params_
best_xgb_model_xg = random_search_cv.best_estimator_

# Evaluating the model
Y_pred = best_xgb_model_xg.predict(X_test)
accuracy = accuracy_score(Y_test, Y_pred)
print("Best hyperparameters:", best_params_xg)
print("Test set accuracy:", accuracy)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score, classification_report
log_reg = LogisticRegression()

# Define the hyperparameter grid for GridSearchCV
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']
}

# Perform GridSearchCV to find the best hyperparameters
grid_search_lg = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5)
grid_search_lg.fit(X_train, Y_train)

# Get the best hyperparameters and the best model
best_params_lg = grid_search_lg.best_params_
best_log_reg_model = grid_search_lg.best_estimator_

# Evaluating the model
y_pred_lg = best_log_reg_model.predict(X_test)
accuracy = accuracy_score(Y_test, y_pred_lg)
print(classification_report(Y_test,y_pred_lg))
print("Best hyperparameters:", best_params_lg)
print("Test set accuracy:", accuracy)
plt.figure(figsize=(10,8))
sns.heatmap(confusion_matrix(Y_test, y_pred_lg),annot=True)
plt.xlabel('predicted-y')
plt.ylabel('actual-y');

#Checking predictions
#0-iris-setosa
#1-iris-versicolor
#2-iris-verginica
y_predict_lg=best_log_reg_model.predict([[5.9,3.0,5.1,1.8]])
print(*y_predict_lg)